{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install llama-index openai pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from constants import openai_key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key   \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    SQLDatabase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"pinecone_api_key\")\n",
    "\n",
    "# pc.create_index(\n",
    "#     name=\"quickstart\",\n",
    "#     dimension=8, # Replace with your model dimensions\n",
    "#     metric=\"euclidean\", # Replace with your model metric\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-west-2\"\n",
    "#     ) \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 8,\n",
       " 'host': 'quickstart-io58o92.svc.apw5-4e34-81fa.pinecone.io',\n",
       " 'metric': 'euclidean',\n",
       " 'name': 'quickstart',\n",
       " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-west-2'}},\n",
       " 'status': {'ready': True, 'state': 'Ready'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.describe_index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_index = pc.Index('quickstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.storage import StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index.node_parser import TokenTextSplitter\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# define node parser and LLM\n",
    "chunk_size = 1024\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\", streaming=True)\n",
    "service_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\n",
    "node_parser = TokenTextSplitter(chunk_size=chunk_size)\n",
    "\n",
    "# define pinecone vector index\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pc_index, namespace=\"ipeds\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_index = VectorStoreIndex([], storage_context=storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "('Troy University-Phenix City Campus', 'Phenix City', 'AL')\n",
      "Table Names:\n",
      "EFFY2022\n",
      "C2022_C\n",
      "SFA2122\n",
      "GR2022\n",
      "C2022_B\n",
      "GR200_22\n",
      "OM2022\n",
      "GR2022_PELL_SSL\n",
      "IC2022\n",
      "SFAV2122\n",
      "C2022DEP\n",
      "EFIA2022\n",
      "C2022_A\n",
      "HD2022\n",
      "IC2022_PY\n",
      "EFFY2022_DIST\n",
      "ADM2022\n",
      "FLAGS2022\n",
      "IC2022_CAMPUSES\n",
      "GR2022_L2\n",
      "IC2022_AY\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def connect_to_database():\n",
    "    # Database connection URL\n",
    "    url = 'postgresql+psycopg2://USER:PASSWORD@HOST:PORT/DB_NAME'\n",
    "\n",
    "    # Creating a SQLAlchemy engine\n",
    "    engine = create_engine(url)\n",
    "\n",
    "    # Creating session\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    # connection and a cursor\n",
    "    connection = engine.connect()\n",
    "    cursor = connection.connection.cursor()\n",
    "\n",
    "    return connection, cursor, engine\n",
    "\n",
    "def execute_query(cursor, query):\n",
    "    # Executing the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Commiting the changes\n",
    "    connection.commit()\n",
    "\n",
    "    # Fetching the data\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    return result\n",
    "\n",
    "# SQL Query\n",
    "sql_query = '''\n",
    "        Select IC.campusid, IC.pcaddr, IC.pccity\n",
    "        from public.\"ADM2022\" as ADM\n",
    "        inner join public.\"IC2022_CAMPUSES\" as IC\n",
    "        on ADM.unitid = IC.index\n",
    "        where ADM.admcon8 = 1\n",
    "        limit 1;    \n",
    "'''\n",
    "\n",
    "# Function to print table names using Metadata\n",
    "def print_table_names(engine):\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(bind=engine)\n",
    "    table_names = metadata.tables.keys()\n",
    "\n",
    "    print(\"Table Names:\")\n",
    "    for table_name in table_names:\n",
    "        print(table_name)\n",
    "\n",
    "# Connect to the database\n",
    "connection, cursor, engine = connect_to_database()\n",
    "\n",
    "# Execute the SQL query\n",
    "results = execute_query(cursor, sql_query)\n",
    "\n",
    "# Display the results\n",
    "print(\"Results:\")\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "# Print all table names\n",
    "print_table_names(engine)\n",
    "\n",
    "# Close the cursor and connection when done\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "# # Replace 'USER', 'PASSWORD', and 'your_database_name' with your actual credentials and database name\n",
    "# database_url = 'postgresql+psycopg2://USER:PASSWORD@db-postgresql-nyc3-10726-do-user-15531455-0.c.db.ondigitalocean.com:25060/your_database_name'\n",
    "# engine = create_engine(database_url)\n",
    "\n",
    "# List of table names\n",
    "table_names = [\n",
    "    \"EFFY2022\",\n",
    "    \"C2022_C\",\n",
    "    \"SFA2122\",\n",
    "    \"GR2022\",\n",
    "    \"C2022_B\",\n",
    "    \"GR200_22\",\n",
    "    \"OM2022\",\n",
    "    \"GR2022_PELL_SSL\",\n",
    "    \"IC2022\",\n",
    "    \"SFAV2122\",\n",
    "    \"C2022DEP\",\n",
    "    \"EFIA2022\",\n",
    "    \"C2022_A\",\n",
    "    \"HD2022\",\n",
    "    \"IC2022_PY\",\n",
    "    \"EFFY2022_DIST\",\n",
    "    \"ADM2022\",\n",
    "    \"FLAGS2022\",\n",
    "    \"IC2022_CAMPUSES\",\n",
    "    \"GR2022_L2\",\n",
    "    \"IC2022_AY\"\n",
    "]\n",
    "\n",
    "# Create a MetaData object and load tables\n",
    "metadata = MetaData()\n",
    "tables = {table_name: Table(table_name, metadata, autoload_with=engine) for table_name in table_names}\n",
    "\n",
    "# Create SQL index\n",
    "sql_database = SQLDatabase(engine, include_tables=table_names)\n",
    "sql_query_engine = NLSQLTableQueryEngine(sql_database=sql_database, tables=table_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'id_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m EFFY2022 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(table_names):\n\u001b[0;32m----> 2\u001b[0m     nodes \u001b[39m=\u001b[39m node_parser\u001b[39m.\u001b[39;49mget_nodes_from_documents([EFFY2022])\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[1;32m      5\u001b[0m         node\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m : EFFY2022}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/node_parser/interface.py:64\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[0;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_nodes_from_documents\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     documents: Sequence[Document],\n\u001b[1;32m     54\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     56\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[1;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse documents into nodes.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     doc_id_to_document \u001b[39m=\u001b[39m {doc\u001b[39m.\u001b[39mid_: doc \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents}\n\u001b[1;32m     66\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m     67\u001b[0m         CBEventType\u001b[39m.\u001b[39mNODE_PARSING, payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m     68\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m     69\u001b[0m         nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_nodes(documents, show_progress\u001b[39m=\u001b[39mshow_progress, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/node_parser/interface.py:64\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_nodes_from_documents\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     documents: Sequence[Document],\n\u001b[1;32m     54\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     56\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[1;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse documents into nodes.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     doc_id_to_document \u001b[39m=\u001b[39m {doc\u001b[39m.\u001b[39;49mid_: doc \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents}\n\u001b[1;32m     66\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m     67\u001b[0m         CBEventType\u001b[39m.\u001b[39mNODE_PARSING, payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m     68\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m     69\u001b[0m         nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_nodes(documents, show_progress\u001b[39m=\u001b[39mshow_progress, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'id_'"
     ]
    }
   ],
   "source": [
    "for EFFY2022 in zip(table_names):\n",
    "    nodes = node_parser.get_nodes_from_documents([EFFY2022])\n",
    "\n",
    "    for node in nodes:\n",
    "        node.metadata = {\"title\" : EFFY2022}\n",
    "    vector_index.insert(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
